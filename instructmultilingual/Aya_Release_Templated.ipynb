{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba9a655-9948-46f3-8afe-c842b2de34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce5dfa69-ba17-4374-94b0-e299c50a7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_BASE_DIR = \"../aya-data-notebooks/AYA-collection-prep/templated-v2/\"\n",
    "\n",
    "TEMP_INFO_FILES = \"../aya-data-notebooks/AYA-collection-prep/templated-v2/info\"\n",
    "\n",
    "templated_data_files = [data_file for data_file in os.listdir(f\"{TEMPLATE_BASE_DIR}data/\") if '.ipynb_checkpoints' not in data_file]\n",
    "\n",
    "templated_info_files = [info_file for info_file in os.listdir(f\"{TEMP_INFO_FILES}\") if '.ipynb_checkpoints' not in info_file]\n",
    "\n",
    "print(len(templated_data_files))\n",
    "print(len(templated_info_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bf622b1-b0a4-4407-9cf8-f085c0edc316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_BASE_DIR = \"../aya-data-notebooks/AYA-collection-prep/templated-remain-v2/\" \n",
    "\n",
    "#'/home/shivalikasingh95/aya_collection_plots/templated_datasets/release-v0-vm/'\n",
    "\n",
    "templated_team3_data_files = [data_file for data_file in os.listdir(f\"{TEMPLATE_BASE_DIR}data/\") if '.ipynb_checkpoints' not in data_file]\n",
    "\n",
    "# team3_data_files = ['joke_explaination_data.jsonl','Xwikis_data.jsonl','SODA_data.jsonl','xlel_wd_data.jsonl','AfriQA_data.jsonl','masakhane-news_data.jsonl',\n",
    "#                     'AfriSenti_data.jsonl','scirepeval_data.jsonl','NusaX-senti_data.jsonl','X-CSQA_data.jsonl','turku_paraphrase_corpus_data.jsonl',\n",
    "#                     'Wiki_split_data.jsonl','Mintaka_data.jsonl']\n",
    "templated_team3_info_files = [info_file for info_file in os.listdir(f\"{TEMPLATE_BASE_DIR}info/\") if '.ipynb_checkpoints' not in info_file]\n",
    "\n",
    "print(len(templated_team3_data_files))\n",
    "print(len(templated_team3_info_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09a8ba0-fe4f-4bb4-81fa-e650649131fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['templated_masakhanews_data.jsonl',\n",
       " 'templated_scirepeval_data.jsonl',\n",
       " 'templated_xcsqa_data.jsonl',\n",
       " 'templated_soda_data.jsonl',\n",
       " 'templated_xlel_wd_data.jsonl',\n",
       " 'templated_turku_paraphrase_data.jsonl',\n",
       " 'templated_nusax_senti_data.jsonl',\n",
       " 'templated_joke_explaination_data.jsonl',\n",
       " 'templated_afrisenti_data.jsonl',\n",
       " 'templated_afriqa_data.jsonl',\n",
       " 'templated_mintaka_data.jsonl',\n",
       " 'templated_xwikis_data.jsonl',\n",
       " 'templated_wiki_split_data.jsonl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templated_team3_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43dd1057-cb8b-495e-8d9b-8e29bd20a028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['templated_soda_info.jsonl',\n",
       " 'templated_turku_paraphrase_info.jsonl',\n",
       " 'templated_mintaka_info.jsonl',\n",
       " 'templated_joke_explaination_info.jsonl',\n",
       " 'templated_xcsqa_info.jsonl',\n",
       " 'templated_nusax_senti_info.jsonl',\n",
       " 'templated_masakhanews_info.jsonl',\n",
       " 'templated_xlel_wd_info.jsonl',\n",
       " 'templated_scirepeval_info.jsonl',\n",
       " 'templated_wiki_split_info.jsonl',\n",
       " 'templated_xwikis_info.jsonl',\n",
       " 'templated_afrisenti_info.jsonl',\n",
       " 'templated_afriqa_info.jsonl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templated_team3_info_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0e19fe6e-69b9-4238-a1c1-3122c0785e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset: templated_wiki_split_data.jsonl\n",
      "dataset_name: templated_wiki_split\n",
      "processing info file: templated_wiki_split_info.jsonl\n"
     ]
    }
   ],
   "source": [
    "data_file = templated_team3_data_files[12] #templated_data_files[30]\n",
    "dataset_name = data_file.replace('_data.jsonl', '')\n",
    "current_data_info = [info_file for info_file in templated_team3_info_files if dataset_name in info_file][0]\n",
    "print(f\"processing dataset: {data_file}\")\n",
    "print(\"dataset_name:\", dataset_name)\n",
    "print(f\"processing info file: {current_data_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "36e56999-6582-4953-b5f0-e6b986e4b3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info_uuid</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sub_dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>template_id</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0e2e8f29-5e53-4227-9559-0dec56150fa3</td>\n",
       "      <td>Wiki-split-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>text-simplification</td>\n",
       "      <td>1</td>\n",
       "      <td>eng</td>\n",
       "      <td>test</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e6edb481-b8b5-4093-90e3-68dcb1a18a75</td>\n",
       "      <td>Wiki-split-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>text-simplification</td>\n",
       "      <td>2</td>\n",
       "      <td>eng</td>\n",
       "      <td>test</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e647ef6-ba76-458c-a064-90edaa66d8d8</td>\n",
       "      <td>Wiki-split-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>text-simplification</td>\n",
       "      <td>1</td>\n",
       "      <td>eng</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de503bfa-96cb-465b-9e2b-89e7a6165e67</td>\n",
       "      <td>Wiki-split-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>text-simplification</td>\n",
       "      <td>2</td>\n",
       "      <td>eng</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e52b6274-b454-4b3b-83d4-5317ecef47d5</td>\n",
       "      <td>Wiki-split-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>text-simplification</td>\n",
       "      <td>1</td>\n",
       "      <td>eng</td>\n",
       "      <td>validation</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ee9bf2a1-6502-465a-8533-c9a1d073e6b4</td>\n",
       "      <td>Wiki-split-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>text-simplification</td>\n",
       "      <td>2</td>\n",
       "      <td>eng</td>\n",
       "      <td>validation</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              info_uuid     dataset_name sub_dataset_name  \\\n",
       "0  0e2e8f29-5e53-4227-9559-0dec56150fa3  Wiki-split-inst                -   \n",
       "1  e6edb481-b8b5-4093-90e3-68dcb1a18a75  Wiki-split-inst                -   \n",
       "2  0e647ef6-ba76-458c-a064-90edaa66d8d8  Wiki-split-inst                -   \n",
       "3  de503bfa-96cb-465b-9e2b-89e7a6165e67  Wiki-split-inst                -   \n",
       "4  e52b6274-b454-4b3b-83d4-5317ecef47d5  Wiki-split-inst                -   \n",
       "5  ee9bf2a1-6502-465a-8533-c9a1d073e6b4  Wiki-split-inst                -   \n",
       "\n",
       "             task_type  template_id language       split script  \n",
       "0  text-simplification            1      eng        test   Latn  \n",
       "1  text-simplification            2      eng        test   Latn  \n",
       "2  text-simplification            1      eng       train   Latn  \n",
       "3  text-simplification            2      eng       train   Latn  \n",
       "4  text-simplification            1      eng  validation   Latn  \n",
       "5  text-simplification            2      eng  validation   Latn  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df = pd.read_json(f\"../aya-data-notebooks/AYA-collection-prep/templated-remain-v2/info/{current_data_info}\", lines=True)\n",
    "info_df\n",
    "\n",
    "# info_df = pd.read_json(f\"{TEMP_INFO_FILES}/{current_data_info}\", lines=True)\n",
    "# info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "906d2f47-4c33-4256-83f2-9983cd73f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info_uuid</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sub_dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>template_id</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f34051c-fb27-4d48-9357-4647d0b71180</td>\n",
       "      <td>Joke-explaination-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>natural-language-generation</td>\n",
       "      <td>1</td>\n",
       "      <td>eng</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8de9dd5d-4260-4a5d-9da6-400050ddcc1a</td>\n",
       "      <td>Joke-explaination-inst</td>\n",
       "      <td>-</td>\n",
       "      <td>natural-language-generation</td>\n",
       "      <td>2</td>\n",
       "      <td>eng</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              info_uuid            dataset_name  \\\n",
       "0  8f34051c-fb27-4d48-9357-4647d0b71180  Joke-explaination-inst   \n",
       "1  8de9dd5d-4260-4a5d-9da6-400050ddcc1a  Joke-explaination-inst   \n",
       "\n",
       "  sub_dataset_name                    task_type  template_id language  split  \\\n",
       "0                -  natural-language-generation            1      eng  train   \n",
       "1                -  natural-language-generation            2      eng  train   \n",
       "\n",
       "  script  \n",
       "0   Latn  \n",
       "1   Latn  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## do clean up\n",
    "info_df_backup = info_df\n",
    "info_df['sub_dataset_name'] = info_df.apply(lambda x: x['sub_dataset_name'].replace(\"_\", \"-\"), axis=1)\n",
    "info_df['task_type'] = info_df.apply(lambda x: x['task_type'].replace(\"nl-generation\", \"natural-language-generation\"), axis=1)\n",
    "info_df.to_json(f\"{TEMP_INFO_FILES}/{current_data_info}\", orient='records', lines=True, force_ascii=False)\n",
    "info_df.to_json(f\"../aya-data-notebooks/AYA-collection-prep/templated-remain-v2/info/{current_data_info}\", orient='records', lines=True, force_ascii=False)\n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9b93a53e-b9da-4880-86f3-38053755b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'validation']\n",
      "curr_split: validation\n"
     ]
    }
   ],
   "source": [
    "splits = list(info_df['split'].unique())\n",
    "print(splits)\n",
    "curr_split = splits[2]\n",
    "print(\"curr_split:\", curr_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c205f02-5fab-4a70-9699-3d8563b4b5ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_split: train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info_uuid</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sub_dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>template_id</th>\n",
       "      <th>language</th>\n",
       "      <th>script</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd439e6d-7690-4891-bfd7-c3d31e1a7589</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>ace</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a4cee95-e266-46a6-ac38-fe64a5b10b6a</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>ace</td>\n",
       "      <td>Latn</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>042cd1b2-b096-4b14-b325-e132d69bf282</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>acm</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d531c08d-6998-4954-962a-5ac25ffd6143</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>acq</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ae3822f-7177-4d1d-b334-11d615cd381c</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>aeb</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>07a9c9c7-f61d-4e5c-8cd2-c5a0db0c6fcf</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>yue</td>\n",
       "      <td>Hant</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>f1435726-418e-49ee-a681-e1d9cc6ab152</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>zho</td>\n",
       "      <td>Hans</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>c55f528b-b68a-4cb2-bc3a-da29ed3094c1</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>zho</td>\n",
       "      <td>Hant</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5b3cdc10-d443-4847-8b47-bc2aa6c270e8</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>zsm</td>\n",
       "      <td>Latn</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>68265ea0-897a-4179-8136-7bd99886d5c8</td>\n",
       "      <td>Flan-CoT-submix (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>generation</td>\n",
       "      <td>1</td>\n",
       "      <td>zul</td>\n",
       "      <td>Latn</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                info_uuid         dataset_name  \\\n",
       "0    cd439e6d-7690-4891-bfd7-c3d31e1a7589  Flan-CoT-submix (T)   \n",
       "1    9a4cee95-e266-46a6-ac38-fe64a5b10b6a  Flan-CoT-submix (T)   \n",
       "2    042cd1b2-b096-4b14-b325-e132d69bf282  Flan-CoT-submix (T)   \n",
       "3    d531c08d-6998-4954-962a-5ac25ffd6143  Flan-CoT-submix (T)   \n",
       "4    0ae3822f-7177-4d1d-b334-11d615cd381c  Flan-CoT-submix (T)   \n",
       "..                                    ...                  ...   \n",
       "115  07a9c9c7-f61d-4e5c-8cd2-c5a0db0c6fcf  Flan-CoT-submix (T)   \n",
       "116  f1435726-418e-49ee-a681-e1d9cc6ab152  Flan-CoT-submix (T)   \n",
       "117  c55f528b-b68a-4cb2-bc3a-da29ed3094c1  Flan-CoT-submix (T)   \n",
       "118  5b3cdc10-d443-4847-8b47-bc2aa6c270e8  Flan-CoT-submix (T)   \n",
       "119  68265ea0-897a-4179-8136-7bd99886d5c8  Flan-CoT-submix (T)   \n",
       "\n",
       "    sub_dataset_name   task_type  template_id language script  split  \n",
       "0                  -  generation            1      ace   Arab  train  \n",
       "1                  -  generation            1      ace   Latn  train  \n",
       "2                  -  generation            1      acm   Arab  train  \n",
       "3                  -  generation            1      acq   Arab  train  \n",
       "4                  -  generation            1      aeb   Arab  train  \n",
       "..               ...         ...          ...      ...    ...    ...  \n",
       "115                -  generation            1      yue   Hant  train  \n",
       "116                -  generation            1      zho   Hans  train  \n",
       "117                -  generation            1      zho   Hant  train  \n",
       "118                -  generation            1      zsm   Latn  train  \n",
       "119                -  generation            1      zul   Latn  train  \n",
       "\n",
       "[120 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_split_df = info_df[info_df['split'] == curr_split]\n",
    "curr_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d46fb-e219-44fb-bca0-af17f4b1134f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410ea0f-7622-4d23-9f58-516fcf54b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_split_dataset = Dataset.from_pandas(curr_split_df, preserve_index=False)\n",
    "curr_split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2390b27-858e-406c-9691-bdb1d8b3847b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info_uuid</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sub_dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>template_id</th>\n",
       "      <th>language</th>\n",
       "      <th>script</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286f5af2-4a52-4a53-b706-a47cce9eaaa4</td>\n",
       "      <td>PIQA (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>question-answering</td>\n",
       "      <td>1</td>\n",
       "      <td>ace</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca2eb5ef-6915-4af0-a7a9-f42899150a2e</td>\n",
       "      <td>PIQA (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>question-answering</td>\n",
       "      <td>1</td>\n",
       "      <td>ace</td>\n",
       "      <td>Latn</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7c7b5bcf-ea7b-4ed2-8a63-7de5d91550f5</td>\n",
       "      <td>PIQA (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>question-answering</td>\n",
       "      <td>1</td>\n",
       "      <td>acm</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5aa61f4d-b108-478a-8e61-ce28f823d86a</td>\n",
       "      <td>PIQA (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>question-answering</td>\n",
       "      <td>1</td>\n",
       "      <td>acq</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500e69af-8d44-4dd2-96b7-d0fd44463c1e</td>\n",
       "      <td>PIQA (T)</td>\n",
       "      <td>-</td>\n",
       "      <td>question-answering</td>\n",
       "      <td>1</td>\n",
       "      <td>aeb</td>\n",
       "      <td>Arab</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              info_uuid dataset_name sub_dataset_name  \\\n",
       "0  286f5af2-4a52-4a53-b706-a47cce9eaaa4     PIQA (T)                -   \n",
       "1  ca2eb5ef-6915-4af0-a7a9-f42899150a2e     PIQA (T)                -   \n",
       "2  7c7b5bcf-ea7b-4ed2-8a63-7de5d91550f5     PIQA (T)                -   \n",
       "3  5aa61f4d-b108-478a-8e61-ce28f823d86a     PIQA (T)                -   \n",
       "4  500e69af-8d44-4dd2-96b7-d0fd44463c1e     PIQA (T)                -   \n",
       "\n",
       "            task_type  template_id language script  split  \n",
       "0  question-answering            1      ace   Arab  train  \n",
       "1  question-answering            1      ace   Latn  train  \n",
       "2  question-answering            1      acm   Arab  train  \n",
       "3  question-answering            1      acq   Arab  train  \n",
       "4  question-answering            1      aeb   Arab  train  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_split_dataset.set_format(\"pandas\")\n",
    "df = curr_split_dataset[:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0bc297a-969b-4530-ba00-bec5fc912e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_split_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247396e-abb2-4d50-bb3f-b717fa94b731",
   "metadata": {},
   "source": [
    "## merge data and info files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "597fc1d3-b09c-4b1e-b3e1-ec85a02369f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "templated_wiki_split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfe6ac38b8644d5b1e3767769305994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7195987aaae8450ca3b319c47163e8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8488f497981d4e4687f2351eb47ba9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/1999888 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'inputs', 'targets', 'info_uuid', 'dataset_name', 'sub_dataset_name', 'task_type', 'template_id', 'language', 'split', 'script'],\n",
       "    num_rows: 1999888\n",
       "})"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset_name)\n",
    "first_file_ds = Dataset.from_json(f\"{TEMPLATE_BASE_DIR}data/{data_file}\")\n",
    "second_file_dict = {x[\"info_uuid\"]: x for x in Dataset.from_json(f\"{TEMPLATE_BASE_DIR}info/{current_data_info}\")} #(f\"{TEMP_INFO_FILES}/{current_data_info}\")}\n",
    "\n",
    "#{x[\"info_uuid\"]: x for x in curr_split_dataset}\n",
    "\n",
    "#   # dict in memory\n",
    "\n",
    "merged_ds = first_file_ds.map(lambda x: second_file_dict[x[\"info_uuid\"]], num_proc=8)  # iteratively writes on disk (the full merged dataset is not in RAM)\n",
    "merged_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e51da17f-0ad6-4a9e-a26f-de0d7c230b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_split: validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66315882749447899ed1325c35c90fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/1999888 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'inputs', 'targets', 'info_uuid', 'dataset_name', 'sub_dataset_name', 'task_type', 'template_id', 'language', 'split', 'script'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"curr_split:\", curr_split)\n",
    "\n",
    "merged_curr_split = merged_ds.filter(lambda example: example[\"split\"]==curr_split, num_proc=8)\n",
    "merged_curr_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "34c369ca-153c-40bc-95d1-7d5f0a2be40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'inputs', 'targets', 'dataset_name', 'sub_dataset_name', 'task_type', 'template_id', 'language', 'split', 'script'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_curr_split\n",
    "merged_curr_split = merged_curr_split.remove_columns(\"info_uuid\")\n",
    "merged_curr_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6504c368-6f90-4b9d-9486-0093caee8ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 994945,\n",
       " 'inputs': \"Please generate a simpler sentence from the following complex sentence:\\n\\\\n' Lauren Rose Crace ' , born 25th of May 1986 in Birmingham , England , currently plays the part of '' Ronnie Mitchell 's '' long lost daughter Danielle Jones ( Amy ) in the soap opera '' EastEnders '' .\",\n",
       " 'targets': \"' Lauren Rose Crace ' , born 25th of May 1986 in Birmingham , England , is the daughter of Jim Crace who is a contemporary English writer .\",\n",
       " 'dataset_name': 'Wiki-split-inst',\n",
       " 'sub_dataset_name': '-',\n",
       " 'task_type': 'text-simplification',\n",
       " 'template_id': 2,\n",
       " 'language': 'eng',\n",
       " 'split': 'validation',\n",
       " 'script': 'Latn'}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_curr_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "288f576d-3529-49c7-b25e-f456851c0876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "templated_wiki_split\n",
      "validation\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)\n",
    "print(curr_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fbfc0b57-f6ff-4a6a-bb2f-1a40f29cc98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c3d8f4d9f94d418fd1193f980f31d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d11eb8ae204e45a3899a9a0b39e0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1547c327fa7243eb9cb808fe2aadfc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/49.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CohereForAI/aya_collection/commit/93abc18d072ef330ce67215bbaf91177744461e4', commit_message='uploading templated_wiki_split validation split', commit_description='', oid='93abc18d072ef330ce67215bbaf91177744461e4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_curr_split.push_to_hub(\"CohereForAI/aya_collection\", config_name=dataset_name, split=curr_split, \n",
    "                                 private=True, token=\"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\", \n",
    "                                 commit_message=f\"uploading {dataset_name} {curr_split} split\",\n",
    "                                 max_shard_size=\"2GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a254c9b5-335a-45e2-8161-725a1ad71e32",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '{' (2665245470.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[40], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    second_file_dict = {x[\"info_id\"]: i for i, x in enumerate(second_file_ds)]  # dict in memory {info_id: example_idx}\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '{'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "first_file_ds = Dataset.from_json(first_file)  # loaded from disk - not in RAM\n",
    "second_file_ds = Dataset.from_json(second_file)  # loaded from disk - not in RAM\n",
    "second_file_dict = {x[\"info_id\"]: i for i, x in enumerate(second_file_ds)]  # dict in memory {info_id: example_idx}\n",
    "\n",
    "merged_ds = first_file_ds.map(lambda x: second_file_ds[second_file_dict[x[\"info_id\"]]])  # iteratively writes on disk (the full merged dataset is not in RAM)\n",
    "\n",
    "\n",
    "# merged_ds.push_to_hub(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf887699-fd2c-4d71-8f51-4186332fa879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3018906"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/stats/translated_data/MLQA_en.csv\")\n",
    "df['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca042c-2313-434d-aaab-7420bbb21b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
