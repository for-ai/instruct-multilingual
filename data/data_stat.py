import json
import datasets
import argparse

# huggingface dataset signature with configs
SERIES_A_DATASET_NAME_DICT = {
	# "udhr": None,
	# "AmazonScience/mintaka": None,
	# "xcsr": [
	# 	'X-CSQA-en', 
	# 	'X-CSQA-zh', 
	# 	'X-CSQA-de', 
	# 	'X-CSQA-es', 
	# 	'X-CSQA-fr', 
	# 	'X-CSQA-it', 
	# 	'X-CSQA-jap', 
	# 	'X-CSQA-nl', 
	# 	'X-CSQA-pl', 
	# 	'X-CSQA-pt', 
	# 	'X-CSQA-ru', 
	# 	'X-CSQA-ar', 
	# 	'X-CSQA-vi', 
	# 	'X-CSQA-hi', 
	# 	'X-CSQA-sw', 
	# 	'X-CSQA-ur', 
	# 	'X-CODAH-en', 
	# 	'X-CODAH-zh', 
	# 	'X-CODAH-de', 
	# 	'X-CODAH-es', 
	# 	'X-CODAH-fr', 
	# 	'X-CODAH-it', 
	# 	'X-CODAH-jap', 
	# 	'X-CODAH-nl', 
	# 	'X-CODAH-pl', 
	# 	'X-CODAH-pt', 
	# 	'X-CODAH-ru', 
	# 	'X-CODAH-ar', 
	# 	'X-CODAH-vi', 
	# 	'X-CODAH-hi', 
	# 	'X-CODAH-sw', 
	# 	'X-CODAH-ur'
	# ],
	# "shmuhammad/AfriSenti-twitter-sentiment": [
	# 	'amh', 
	# 	'hau', 
	# 	'ibo',
	# 	'arq', 
	# 	'ary', 
	# 	'yor', 
	# 	'por', 
	# 	'twi', 
	# 	'tso', 
	# 	'tir', 
	# 	'pcm', 
	# 	'kin', 
	# 	'swa'
	# ], # orm is not workin
	# "indonlp/NusaX-senti": [
	# 	'ace', 
	# 	'ban', 
	# 	'bjn', 
	# 	'bug',
	# 	'eng',
	# 	'ind',
	# 	'jav', 
	# 	'mad', 
	# 	'min', 
	# 	'nij', 
	# 	'sun', 
	# 	'bbc'
	# ],
	"masakhane/masakhanews": [
		'amh', 
		'eng', 
		'fra', 
		'hau', 
		'ibo', 
		'lin', 
		'lug', 
		'orm', 
		'pcm', 
		'run', 
		'sna', 
		'som', 
		'swa', 
		'tir', 
		'xho', 
		'yor'
	],
	"papluca/language-identification": [
		'wikipedia-zero-shot', 
		'wikipedia-zero-shot.af', 
		'wikipedia-zero-shot.ar', 
		'wikipedia-zero-shot.be', 
		'wikipedia-zero-shot.bg', 
		'wikipedia-zero-shot.bn',
		'wikipedia-zero-shot.ca',
		'wikipedia-zero-shot.cs', 
		'wikipedia-zero-shot.da', 
		'wikipedia-zero-shot.de', 
		'wikipedia-zero-shot.el', 
		'wikipedia-zero-shot.en',
		'wikipedia-zero-shot.es',
		'wikipedia-zero-shot.fa', 
		'wikipedia-zero-shot.fi',
		'wikipedia-zero-shot.fr',
		'wikipedia-zero-shot.he',
		'wikipedia-zero-shot.hi',
		'wikipedia-zero-shot.hu',
		'wikipedia-zero-shot.id',
		'wikipedia-zero-shot.it',
		'wikipedia-zero-shot.ja',
		'wikipedia-zero-shot.ko',
		'wikipedia-zero-shot.ml',
		'wikipedia-zero-shot.mr',
		'wikipedia-zero-shot.ms',
		'wikipedia-zero-shot.nl',
		'wikipedia-zero-shot.no',
		'wikipedia-zero-shot.pl',
		'wikipedia-zero-shot.pt',
		'wikipedia-zero-shot.ro',
		'wikipedia-zero-shot.ru',
		'wikipedia-zero-shot.si',
		'wikipedia-zero-shot.sk',
  		'wikipedia-zero-shot.sl',
		'wikipedia-zero-shot.sr', 
		'wikipedia-zero-shot.sv', 
		'wikipedia-zero-shot.sw',
		'wikipedia-zero-shot.ta', 
		'wikipedia-zero-shot.te',
		'wikipedia-zero-shot.th',
		'wikipedia-zero-shot.tr',
		'wikipedia-zero-shot.uk',
		'wikipedia-zero-shot.vi',
		'wikipedia-zero-shot.zh',
		'wikinews-zero-shot',
		'wikinews-zero-shot.ar',
		'wikinews-zero-shot.cs',
		'wikinews-zero-shot.de',
		'wikinews-zero-shot.en',
		'wikinews-zero-shot.es',
		'wikinews-zero-shot.fi', 
		'wikinews-zero-shot.fr',
		'wikinews-zero-shot.it',
		'wikinews-zero-shot.ja',
		'wikinews-zero-shot.ko',
		'wikinews-zero-shot.nl',
		'wikinews-zero-shot.no',
		'wikinews-zero-shot.pl',
		'wikinews-zero-shot.pt',
		'wikinews-zero-shot.ru',
		'wikinews-zero-shot.sr',
		'wikinews-zero-shot.sv',
		'wikinews-zero-shot.ta',
		'wikinews-zero-shot.tr',
		'wikinews-zero-shot.uk',
		'wikinews-zero-shot.zh',
		'wikinews-cross-domain', 
		'wikinews-cross-domain.ar',
		'wikinews-cross-domain.bg',
		'wikinews-cross-domain.ca',
		'wikinews-cross-domain.cs',
		'wikinews-cross-domain.de',
		'wikinews-cross-domain.el',
		'wikinews-cross-domain.en',
		'wikinews-cross-domain.es',
		'wikinews-cross-domain.fi',
		'wikinews-cross-domain.fr',
		'wikinews-cross-domain.he', 
		'wikinews-cross-domain.hu', 
		'wikinews-cross-domain.it', 
		'wikinews-cross-domain.ja',
  		'wikinews-cross-domain.ko',
		'wikinews-cross-domain.nl',
		'wikinews-cross-domain.no',
  		'wikinews-cross-domain.pl',
		'wikinews-cross-domain.pt',
		'wikinews-cross-domain.ro',
  		'wikinews-cross-domain.ru',
		'wikinews-cross-domain.sr',
		'wikinews-cross-domain.sv',
		'wikinews-cross-domain.ta',
	 	'wikinews-cross-domain.tr',
	  	'wikinews-cross-domain.uk', 
		'wikinews-cross-domain.zh'
	],
	"adithya7/xlel_wd": [
		'wikipedia-zero-shot', 
		'wikipedia-zero-shot.af', 
		'wikipedia-zero-shot.ar', 
		'wikipedia-zero-shot.be', 
		'wikipedia-zero-shot.bg',
		'wikipedia-zero-shot.bn',
		'wikipedia-zero-shot.ca',
		'wikipedia-zero-shot.cs',
		'wikipedia-zero-shot.da',
		'wikipedia-zero-shot.de',
		'wikipedia-zero-shot.el',
		'wikipedia-zero-shot.en',
		'wikipedia-zero-shot.es',
		'wikipedia-zero-shot.fa',
		'wikipedia-zero-shot.fi',
		'wikipedia-zero-shot.fr',
		'wikipedia-zero-shot.he',
		'wikipedia-zero-shot.hi',
		'wikipedia-zero-shot.hu', 
		'wikipedia-zero-shot.id',
		'wikipedia-zero-shot.it',
		'wikipedia-zero-shot.ja',
		'wikipedia-zero-shot.ko',
		'wikipedia-zero-shot.ml',
		'wikipedia-zero-shot.mr',
		'wikipedia-zero-shot.ms',
		'wikipedia-zero-shot.nl',
		'wikipedia-zero-shot.no', 
		'wikipedia-zero-shot.pl',
		'wikipedia-zero-shot.pt',
		'wikipedia-zero-shot.ro',
		'wikipedia-zero-shot.ru',
		'wikipedia-zero-shot.si',
		'wikipedia-zero-shot.sk',
		'wikipedia-zero-shot.sl',
		'wikipedia-zero-shot.sr',
		'wikipedia-zero-shot.sv',
		'wikipedia-zero-shot.sw',
		'wikipedia-zero-shot.ta',
		'wikipedia-zero-shot.te',
		'wikipedia-zero-shot.th', 
		'wikipedia-zero-shot.tr',
		'wikipedia-zero-shot.uk',
	 	'wikipedia-zero-shot.vi', 
		'wikipedia-zero-shot.zh',
	 	'wikinews-zero-shot',
	  	'wikinews-zero-shot.ar',
	   	'wikinews-zero-shot.cs',
		'wikinews-zero-shot.de',
		'wikinews-zero-shot.en',
		'wikinews-zero-shot.es',
		'wikinews-zero-shot.fi',
		'wikinews-zero-shot.fr',
		'wikinews-zero-shot.it',
		'wikinews-zero-shot.ja',
		'wikinews-zero-shot.ko',
		'wikinews-zero-shot.nl', 
		'wikinews-zero-shot.no', 
		'wikinews-zero-shot.pl',
	 	'wikinews-zero-shot.pt', 
		'wikinews-zero-shot.ru', 
		'wikinews-zero-shot.sr',
		'wikinews-zero-shot.sv', 
		'wikinews-zero-shot.ta',
	 	'wikinews-zero-shot.tr',
	  	'wikinews-zero-shot.uk',
		'wikinews-zero-shot.zh',
		'wikinews-cross-domain',
		'wikinews-cross-domain.ar',
		'wikinews-cross-domain.bg',
		'wikinews-cross-domain.ca',
		'wikinews-cross-domain.cs',
	 	'wikinews-cross-domain.de',
		'wikinews-cross-domain.el',
	 	'wikinews-cross-domain.en',
	  	'wikinews-cross-domain.es',
	   	'wikinews-cross-domain.fi',
		'wikinews-cross-domain.fr', 
		'wikinews-cross-domain.he', 
		'wikinews-cross-domain.hu', 
		'wikinews-cross-domain.it', 
		'wikinews-cross-domain.ja', 
		'wikinews-cross-domain.ko', 
		'wikinews-cross-domain.nl', 
		'wikinews-cross-domain.no', 
		'wikinews-cross-domain.pl', 
		'wikinews-cross-domain.pt', 
		'wikinews-cross-domain.ro', 
		'wikinews-cross-domain.ru', 
		'wikinews-cross-domain.sr', 
		'wikinews-cross-domain.sv', 
		'wikinews-cross-domain.ta', 
		'wikinews-cross-domain.tr', 
		'wikinews-cross-domain.uk', 
		'wikinews-cross-domain.zh'
	],
	"ted_talks_iwslt": [
		'eu_ca_2014', 
	 	'eu_ca_2015', 
	  	'eu_ca_2016', 
	   	'nl_en_2014', 
		'nl_en_2015', 
		'nl_en_2016', 
		'nl_hi_2014', 
		'nl_hi_2015', 
		'nl_hi_2016', 
		'de_ja_2014', 
		'de_ja_2015', 
		'de_ja_2016', 
		'fr-ca_hi_2014', 
		'fr-ca_hi_2015', 
		'fr-ca_hi_2016'
	]
}

def main():
	parser = argparse.ArgumentParser()
	parser.add_argument(
		"--dataset-names",
		nargs="+",
		default=None,
		help="Print the stat of the dataset. If `None` it will print stat of all the used data."
	)
	args = parser.parse_args()
	stat_dict = {}
	if args.dataset_names is None:
		args.dataset_names = list(SERIES_A_DATASET_NAME_DICT.keys())
	for dataset_name, subset_names in SERIES_A_DATASET_NAME_DICT.items():
		if dataset_name not in args.dataset_names:
			continue
		stat_dict[dataset_name] = {}
		if subset_names is None:
			stat_dict[dataset_name]['Subset(None)'] = {}
			dt = datasets.load_dataset(dataset_name, ignore_verifications=True)
			for split in dt.keys():
				stat_dict[dataset_name]['Subset(None)'][split] = {
					"size": len(dt[split]),
					"column": list(dt[split].column_names),
				}
		else:
			for subset in subset_names:
				assert subset not in stat_dict[dataset_name]
				stat_dict[dataset_name][subset] = {}
				dt = datasets.load_dataset(dataset_name, name=subset, ignore_verifications=True)
				for split in dt.keys():
					stat_dict[dataset_name][subset][split] = {
						"size": len(dt[split]),
						"column": list(dt[split].column_names),
					}

	print(f"{json.dumps(stat_dict, indent=4)}")

if __name__ == "__main__":
	main()
   
